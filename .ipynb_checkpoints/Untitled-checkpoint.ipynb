{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4eef2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Transcribing the data from the image to a pandas DataFrame\n",
    "data = pd.read_csv('res_data_log.csv').iloc[:5000000, 1:]\n",
    "\n",
    "# Creating the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize lists to store metrics for plotting\n",
    "r2_scores_lgbm_train, r2_scores_lgbm_test = [], []\n",
    "mae_scores_lgbm_train, mae_scores_lgbm_test = [], []\n",
    "mse_scores_lgbm_train, mse_scores_lgbm_test = [], []\n",
    "\n",
    "r2_scores_mlp_train, r2_scores_mlp_test = [], []\n",
    "mae_scores_mlp_train, mae_scores_mlp_test = [], []\n",
    "mse_scores_mlp_train, mse_scores_mlp_test = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "330689b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A = 1:\n",
      "==================: 1\n",
      "LightGBM - R² (Train): 0.9997852802795328\n",
      "LightGBM - R² (Validation): 0.9533754632573832\n",
      "LightGBM - MAE (Train): 2.8293929676898228e-05\n",
      "LightGBM - MAE (Validation): 2.2092623268186875e-06\n",
      "LightGBM - MSE (Train): 1.5840415894586943e-08\n",
      "LightGBM - MSE (Validation): 6.890814019784001e-12\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1,) and (2,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 104\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# R2 Score Plot\u001b[39;00m\n\u001b[0;32m    103\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 104\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, A \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), r2_scores_lgbm_train, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLightGBM Train R²\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    105\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, A \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), r2_scores_lgbm_test, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLightGBM Validation R²\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    106\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\pyplot.py:2812\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2810\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   2811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   2813\u001b[0m         \u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39mscalex, scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   2814\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1685\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1688\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1689\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1690\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plot_args(\n\u001b[0;32m    312\u001b[0m     this, kwargs, ambiguous_fmt_datakey\u001b[38;5;241m=\u001b[39mambiguous_fmt_datakey)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1,) and (2,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = 1\n",
    "\n",
    "for A in range(1, 2):\n",
    "    print(f\"\\nA = {A}:\")\n",
    "\n",
    "    # Feature engineering: create lag features for the past A observations\n",
    "    for i in range(A, A + 10):\n",
    "        df[f'prey_lag_{i}'] = df['prey'].shift(i)\n",
    "        df[f'predator_lag_{i}'] = df['predator'].shift(i)\n",
    "\n",
    "    # Drop rows with NaN values created by shifting\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Prepare the data for LightGBM\n",
    "    target = 'predator'\n",
    "    features = [f for f in df.columns if f not in ['time', target]]\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "\n",
    "    # Define the index to split the data into training and validation sets\n",
    "    split_index = int(0.5 * len(df))  # 50% of the data for training\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val = X.iloc[:split_index], X.iloc[split_index:]\n",
    "    y_train, y_val = y.iloc[:split_index], y.iloc[split_index:]\n",
    "\n",
    "    # Define LightGBM parameters\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'l2',\n",
    "        'verbose': -1,\n",
    "        'n_estimators': 1000\n",
    "    }\n",
    "\n",
    "    # Initialize the model\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train,\n",
    "              eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "              eval_metric=['l2', 'l1'],\n",
    "              #early_stopping_rounds=20,\n",
    "              #verbose=False\n",
    "              )\n",
    "\n",
    "    # Predict on the training and validation sets\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_val = model.predict(X_val)\n",
    "\n",
    "    # Calculate metrics for LightGBM\n",
    "    r2_train_lgbm = r2_score(y_train, y_pred_train)\n",
    "    r2_val_lgbm = r2_score(y_val, y_pred_val)\n",
    "    mae_train_lgbm = mean_absolute_error(y_train, y_pred_train)\n",
    "    mae_val_lgbm = mean_absolute_error(y_val, y_pred_val)\n",
    "    mse_train_lgbm = mean_squared_error(y_train, y_pred_train)\n",
    "    mse_val_lgbm = mean_squared_error(y_val, y_pred_val)\n",
    "\n",
    "    # Store metrics for plotting\n",
    "    r2_scores_lgbm_train.append(r2_train_lgbm)\n",
    "    r2_scores_lgbm_test.append(r2_val_lgbm)\n",
    "    mae_scores_lgbm_train.append(mae_train_lgbm)\n",
    "    mae_scores_lgbm_test.append(mae_val_lgbm)\n",
    "    mse_scores_lgbm_train.append(mse_train_lgbm)\n",
    "    mse_scores_lgbm_test.append(mse_val_lgbm)\n",
    "\n",
    "    # Initialize the MLPRegressor model\n",
    "    model1 = MLPRegressor(hidden_layer_sizes=(32,), activation='relu', solver='adam', max_iter=1000, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    model1.fit(X_train, y_train)  # Use X_train, y_train instead of X_train1, y_train1\n",
    "\n",
    "    # Predict on the training and validation sets\n",
    "    y_pred_train_mlp = model1.predict(X_train)\n",
    "    y_pred_val_mlp = model1.predict(X_val)\n",
    "\n",
    "    # Calculate metrics for MLPRegressor\n",
    "    r2_train_mlp = r2_score(y_train, y_pred_train_mlp)\n",
    "    r2_val_mlp = r2_score(y_val, y_pred_val_mlp)\n",
    "    mae_train_mlp = mean_absolute_error(y_train, y_pred_train_mlp)\n",
    "    mae_val_mlp = mean_absolute_error(y_val, y_pred_val_mlp)\n",
    "    mse_train_mlp = mean_squared_error(y_train, y_pred_train_mlp)\n",
    "    mse_val_mlp = mean_squared_error(y_val, y_pred_val_mlp)\n",
    "\n",
    "    # Store metrics for plotting\n",
    "    r2_scores_mlp_train.append(r2_train_mlp)\n",
    "    r2_scores_mlp_test.append(r2_val_mlp)\n",
    "    mae_scores_mlp_train.append(mae_train_mlp)\n",
    "    mae_scores_mlp_test.append(mae_val_mlp)\n",
    "    mse_scores_mlp_train.append(mse_train_mlp)\n",
    "    mse_scores_mlp_test.append(mse_val_mlp)\n",
    "\n",
    "    print(\"==================:\", A)\n",
    "    print(\"LightGBM - R² (Train):\", r2_train_lgbm)\n",
    "    print(\"LightGBM - R² (Validation):\", r2_val_lgbm)\n",
    "    print(\"LightGBM - MAE (Train):\", mae_train_lgbm)\n",
    "    print(\"LightGBM - MAE (Validation):\", mae_val_lgbm)\n",
    "    print(\"LightGBM - MSE (Train):\", mse_train_lgbm)\n",
    "    print(\"LightGBM - MSE (Validation):\", mse_val_lgbm)\n",
    "\n",
    "\n",
    "    # Plot and save figures\n",
    "    plt.figure(figsize=(10,10))\n",
    "\n",
    "    # R2 Score Plot\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(range(1, A + 1), r2_scores_lgbm_train, label='LightGBM Train R²')\n",
    "    plt.plot(range(1, A + 1), r2_scores_lgbm_test, label='LightGBM Validation R²')\n",
    "    plt.xlabel('A')\n",
    "    plt.ylabel('R²')\n",
    "    plt.title('R² Score')\n",
    "    plt.legend()\n",
    "    #plt.savefig(f'R2_Score_A_{A}.png')\n",
    "\n",
    "    # MAE Score Plot\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(range(1, A + 1), mae_scores_lgbm_train, label='LightGBM Train MAE')\n",
    "    plt.plot(range(1, A + 1), mae_scores_lgbm_test, label='LightGBM Validation MAE')\n",
    "    plt.xlabel('A')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('MAE Score')\n",
    "    plt.legend()\n",
    "    #plt.savefig(f'MAE_Score_A_{A}.png')\n",
    "\n",
    "    # MSE Score Plot\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(range(1, A + 1), mse_scores_lgbm_train, label='LightGBM Train MSE')\n",
    "    plt.plot(range(1, A + 1), mse_scores_lgbm_test, label='LightGBM Validation MSE')\n",
    "    plt.xlabel('A')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title('MSE Score')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig(f'LGM_Score_A_{A}.png')\n",
    "\n",
    "    # Clear the plot\n",
    "    plt.clf()\n",
    "\n",
    "    #MLP\n",
    "    print(\"MLPRegressor - R² (Train):\", r2_train_mlp)\n",
    "    print(\"MLPRegressor - R² (Validation):\", r2_val_mlp)\n",
    "    print(\"MLPRegressor - MAE (Train):\", mae_train_mlp)\n",
    "    print(\"MLPRegressor - MAE (Validation):\", mae_val_mlp)\n",
    "    print(\"MLPRegressor - MSE (Train):\", mse_train_mlp)\n",
    "    print(\"MLPRegressor - MSE (Validation):\", mse_val_mlp)\n",
    "\n",
    "    #MLP_r2\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(range(1, A + 1), r2_scores_mlp_train, label='MLPRegressor Train R²')\n",
    "    plt.plot(range(1, A + 1), r2_scores_mlp_test, label='MLPRegressor Validation R²')\n",
    "    plt.xlabel('A')\n",
    "    plt.ylabel('R²')\n",
    "    plt.title('R² Score')\n",
    "    plt.legend()\n",
    "\n",
    "    #MAE\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(range(1, A + 1), mae_scores_mlp_train, label='MLPRegressor Train MAE')\n",
    "    plt.plot(range(1, A + 1), mae_scores_mlp_test, label='MLPRegressor Validation MAE')\n",
    "    plt.xlabel('A')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('MAE Score')\n",
    "    plt.legend()\n",
    "\n",
    "    #MSE\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(range(1, A + 1), mse_scores_mlp_train, label='MLPRegressor Train MSE')\n",
    "    plt.plot(range(1, A + 1), mse_scores_mlp_test, label='MLPRegressor Validation MSE')\n",
    "    plt.xlabel('A')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title('MSE Score')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.savefig(f'MLP_Score_A_{A}.png')\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eafac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586c993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for A in range(1, 11):\n",
    "    print(f\"\\nA = {A}:\")\n",
    "\n",
    "    # Feature engineering: create lag features for the past A observations\n",
    "    for i in range(A, A + 10):\n",
    "        df[f'prey_lag_{i}'] = df['prey'].shift(i)\n",
    "        df[f'predator_lag_{i}'] = df['predator'].shift(i)\n",
    "\n",
    "    # Drop rows with NaN values created by shifting\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Prepare the data for LightGBM\n",
    "    target = 'predator'\n",
    "    features = [f for f in df.columns if f not in ['time', target]]\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "\n",
    "    # Define the index to split the data into training and validation sets\n",
    "    split_index = int(0.5 * len(df))  # 50% of the data for training\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val = X.iloc[:split_index], X.iloc[split_index:]\n",
    "    y_train, y_val = y.iloc[:split_index], y.iloc[split_index:]\n",
    "\n",
    "    # Define LightGBM parameters\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'l2',\n",
    "        'verbose': -1,\n",
    "        'n_estimators': 1000\n",
    "    }\n",
    "\n",
    "    # Initialize the model\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train,\n",
    "              eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "              eval_metric=['l2', 'l1'],\n",
    "              #early_stopping_rounds=20,\n",
    "              #verbose=False\n",
    "              )\n",
    "\n",
    "    # Predict on the training and validation sets\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_val = model.predict(X_val)\n",
    "\n",
    "    # Calculate metrics for LightGBM\n",
    "    r2_train_lgbm = r2_score(y_train, y_pred_train)\n",
    "    r2_val_lgbm = r2_score(y_val, y_pred_val)\n",
    "    mae_train_lgbm = mean_absolute_error(y_train, y_pred_train)\n",
    "    mae_val_lgbm = mean_absolute_error(y_val, y_pred_val)\n",
    "    mse_train_lgbm = mean_squared_error(y_train, y_pred_train)\n",
    "    mse_val_lgbm = mean_squared_error(y_val, y_pred_val)\n",
    "\n",
    "    # Store metrics for plotting\n",
    "    r2_scores_lgbm_train.append(r2_train_lgbm)\n",
    "    r2_scores_lgbm_test.append(r2_val_lgbm)\n",
    "    mae_scores_lgbm_train.append(mae_train_lgbm)\n",
    "    mae_scores_lgbm_test.append(mae_val_lgbm)\n",
    "    mse_scores_lgbm_train.append(mse_train_lgbm)\n",
    "    mse_scores_lgbm_test.append(mse_val_lgbm)\n",
    "\n",
    "    # Initialize the MLPRegressor model\n",
    "    model1 = MLPRegressor(hidden_layer_sizes=(32,), activation='relu', solver='adam', max_iter=1000, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    model1.fit(X_train, y_train)  # Use X_train, y_train instead of X_train1, y_train1\n",
    "\n",
    "    # Predict on the training and validation sets\n",
    "    y_pred_train_mlp = model1.predict(X_train)\n",
    "    y_pred_val_mlp = model1.predict(X_val)\n",
    "\n",
    "    # Calculate metrics for MLPRegressor\n",
    "    r2_train_mlp = r2_score(y_train, y_pred_train_mlp)\n",
    "    r2_val_mlp = r2_score(y_val, y_pred_val_mlp)\n",
    "    mae_train_mlp = mean_absolute_error(y_train, y_pred_train_mlp)\n",
    "    mae_val_mlp = mean_absolute_error(y_val, y_pred_val_mlp)\n",
    "    mse_train_mlp = mean_squared_error(y_train, y_pred_train_mlp)\n",
    "    mse_val_mlp = mean_squared_error(y_val, y_pred_val_mlp)\n",
    "\n",
    "    # Store metrics for plotting\n",
    "    r2_scores_mlp_train.append(r2_train_mlp)\n",
    "    r2_scores_mlp_test.append(r2_val_mlp)\n",
    "    mae_scores_mlp_train.append(mae_train_mlp)\n",
    "    mae_scores_mlp_test.append(mae_val_mlp)\n",
    "    mse_scores_mlp_train.append(mse_train_mlp)\n",
    "    mse_scores_mlp_test.append(mse_val_mlp)\n",
    "\n",
    "    print(\"==================:\", A)\n",
    "    print(\"LightGBM - R² (Train):\", r2_train_lgbm)\n",
    "    print(\"LightGBM - R² (Validation):\", r2_val_lgbm)\n",
    "    print(\"LightGBM - MAE (Train):\", mae_train_lgbm)\n",
    "    print(\"LightGBM - MAE (Validation):\", mae_val_lgbm)\n",
    "    print(\"LightGBM - MSE (Train):\", mse_train_lgbm)\n",
    "    print(\"LightGBM - MSE (Validation):\", mse_val_lgbm)\n",
    "\n",
    "\n",
    "    # Plot and save figures\n",
    "    plt.figure(figsize=(20,9))\n",
    "\n",
    "    # R2 Score Plot\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(range(1, A + 1), r2_scores_lgbm_train, label='LightGBM Train R²')\n",
    "    plt.plot(range(1, A + 1), r2_scores_lgbm_test, label='LightGBM Validation R²')\n",
    "    plt.xlabel('A')\n",
    "    plt.ylabel('R²')\n",
    "    plt.title('R² Score')\n",
    "    plt.legend()\n",
    "    #plt.savefig(f'R2_Score_A_{A}.png')\n",
    "\n",
    "    # MAE Score Plot\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(range(1, A + 1), mae_scores_lgbm_train, label='LightGBM Train MAE')\n",
    "    plt.plot(range(1, A + 1), mae_scores_lgbm_test, label='LightGBM Validation MAE')\n",
    "    plt.xlabel('A')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('MAE Score')\n",
    "    plt.legend()\n",
    "    #plt.savefig(f'MAE_Score_A_{A}.png')\n",
    "\n",
    "    # MSE Score Plot\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(range(1, A + 1), mse_scores_lgbm_train, label='LightGBM Train MSE')\n",
    "    plt.plot(range(1, A + 1), mse_scores_lgbm_test, label='LightGBM Validation MSE')\n",
    "    plt.xlabel('A')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title('MSE Score')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig(f'LGM_Score_A_{A}.png')\n",
    "\n",
    "    # Clear the plot\n",
    "    plt.clf()\n",
    "\n",
    "    #MLP\n",
    "    print(\"MLPRegressor - R² (Train):\", r2_train_mlp)\n",
    "    print(\"MLPRegressor - R² (Validation):\", r2_val_mlp)\n",
    "    print(\"MLPRegressor - MAE (Train):\", mae_train_mlp)\n",
    "    print(\"MLPRegressor - MAE (Validation):\", mae_val_mlp)\n",
    "    print(\"MLPRegressor - MSE (Train):\", mse_train_mlp)\n",
    "    print(\"MLPRegressor - MSE (Validation):\", mse_val_mlp)\n",
    "\n",
    "    #MLP_r2\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(range(1, A + 1), r2_scores_mlp_train, label='MLPRegressor Train R²')\n",
    "    plt.plot(range(1, A + 1), r2_scores_mlp_test, label='MLPRegressor Validation R²')\n",
    "    plt.xlabel('A')\n",
    "    plt.ylabel('R²')\n",
    "    plt.title('R² Score')\n",
    "    plt.legend()\n",
    "\n",
    "    #MAE\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(range(1, A + 1), mae_scores_mlp_train, label='MLPRegressor Train MAE')\n",
    "    plt.plot(range(1, A + 1), mae_scores_mlp_test, label='MLPRegressor Validation MAE')\n",
    "    plt.xlabel('A')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('MAE Score')\n",
    "    plt.legend()\n",
    "\n",
    "    #MSE\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(range(1, A + 1), mse_scores_mlp_train, label='MLPRegressor Train MSE')\n",
    "    plt.plot(range(1, A + 1), mse_scores_mlp_test, label='MLPRegressor Validation MSE')\n",
    "    plt.xlabel('A')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title('MSE Score')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.savefig(f'MLP_Score_A_{A}.png')\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4127e1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
